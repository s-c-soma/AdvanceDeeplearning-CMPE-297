{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExtraCredit_Assignment_3_Part_D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-c-soma/AdvanceDeeplearning-CMPE-297/blob/master/Assignment_3/ExtraCredit_Assignment_3_Part_D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I37oDade0s5y"
      },
      "source": [
        "# Assignment 3 Part D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3HH_E0dqaIw"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih5NlvdDEOI1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEEkA2fV1CIs"
      },
      "source": [
        "## SIMCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3_TqFaRtfeg"
      },
      "source": [
        "class simclr(object):\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "\n",
        "    def resnet_simclr(self, layer1, layer2, layer3):\n",
        "        model = tf.keras.applications.ResNet50(include_top=False, weights=None, input_shape=(224,224,3))\n",
        "        model.trainable = True\n",
        "        inputs = Input((224,224,3))\n",
        "        h = model(inputs, trainable=True)\n",
        "        h = GlobalAveragePooling2D()(h)\n",
        "\n",
        "        layer1_projection = Dense(layer1)(h)\n",
        "        layer1_activation = Activation(\"relu\")(layer1_projection)\n",
        "        layer2_projection = Dense(layer2)(layer1_activation)\n",
        "        layer2_activation = Activation(\"relu\")(layer2_projection)\n",
        "        layer3_projection = Dense(layer3)(layer2_activation)\n",
        "\n",
        "        resnet_simclr_model = Model(inputs, layer3_projection)\n",
        "\n",
        "        return resnet_simclr_model\n",
        "\n",
        "    def train_step(self, input1, input2, model, optimizer, criterion, temperature):\n",
        "        with tf.GradientTape() as tape:\n",
        "            norm_input1 = model(input1)\n",
        "            norm_input1 = tf.math.l2_normalize(norm_input1, axis=1)\n",
        "            norm_input2 = model(input2)\n",
        "            norm_input2 = tf.math.l2_normalize(norm_input2, axis=1)\n",
        "\n",
        "            simililarity_pos = _dot_simililarity_dim1(norm_input1, norm_input2)\n",
        "            simililarity_pos = tf.reshape(simililarity_pos, (self.batch_size, 1))\n",
        "            simililarity_pos /= temperature\n",
        "\n",
        "            negatives = tf.concat([norm_input1, norm_input2], axis=0)\n",
        "\n",
        "            loss = 0\n",
        "\n",
        "            for positives in [norm_input1, norm_input2]:\n",
        "                simililarity_neg = _dot_simililarity_dim2(positives, negatives)\n",
        "\n",
        "                labels = tf.zeros(self.batch_size, dtype=tf.int32)\n",
        "\n",
        "                negative_mask = get_negative_mask(self.batch_size)\n",
        "                simililarity_neg = tf.boolean_mask(simililarity_neg, negative_mask)\n",
        "                simililarity_neg = tf.reshape(simililarity_neg, (self.batch_size, -1))\n",
        "                simililarity_neg /= temperature\n",
        "\n",
        "                logits = tf.concat([simililarity_pos, simililarity_neg])\n",
        "                loss += criterion(logits, labels)\n",
        "\n",
        "            loss /= 2 * self.batch_size\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLISBYFJrLqS"
      },
      "source": [
        "def _dot_simililarity_dim1(x, y):\n",
        "    v = tf.matmul(tf.expand_dims(x, 1), tf.expand_dims(y, 2))\n",
        "    return v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsWuZ8FTrQgQ"
      },
      "source": [
        "def _dot_simililarity_dim2(x, y):\n",
        "    v = tf.tensordot(tf.expand_dims(x, 1), tf.expand_dims(tf.transpose(y), 0), axes=2)\n",
        "    return v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WXspghpERRG"
      },
      "source": [
        "def get_negative_mask(batch_size):\n",
        "    negative_mask = np.ones((batch_size, 2 * batch_size), dtype=bool)\n",
        "    for i in range(batch_size):\n",
        "        negative_mask[i, i] = 0\n",
        "        negative_mask[i, i + batch_size] = 0\n",
        "    return tf.constant(negative_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWvT0gAhssx_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2458319a-c61a-4ae1-d50d-d62894bfee03"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    print(tf.__version__)\n",
        "    simclr1=simclr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}